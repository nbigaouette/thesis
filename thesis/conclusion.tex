\section{Conclusion}

Clusters of atoms are without a doubt an extremely useful tool to study
laser and matter interaction. They were in used even before atoms were discovered
for their optical properties. With the advancement of both clusters creation
and laser technologies, it became possible to gain a significant understanding
on how light interacts with matter. Clusters studies thus became an important
physics research area.

At the simplest level, quantum mechanic describes the dynamics but exact solutions
are not possible for systems of more than two electrons.
The process of photo-ionization of single atoms is known, but the high density
of atoms inside clusters gives rise to interesting phenomena. It was a surprise
to scientists ten years ago to see highly charged ions coming out of experiments
using rare gas clusters with short duration (tens of femtoseconds), high intensity
(10$^{12}$ -- 10$^{14}$ W/cm$^2$) and small wavelength (VUV, XUV) laser pulses.
More than ten years later, our understanding of the different mechanisms of energy
absorption and diffusion throughout the cluster is taking shape. Even though full
quantum mechanical description of clusters is not possible, small approximations
can be taken, allowing theoretical and numerical studies to be performed.

Our numerical tool of choice is Molecular Dynamics where we track, classically,
the dynamics of electrons and ions during and after a laser pulse. MD simulations,
being classical systems, allows a larger number of particles than full quantum
simulations but can still describe the large fluctuations in charge and field
generated inside a cluster.

Many different MD packages are available freely that could have been used for
the current work. After a first try with one such package, it was decided to
start from scratch a new one. The MD algorithm is relatively simple; having
control on the rest of the package allowed flexibility in the development that
would have not been possible with a third party package. Fore example, existing
MD codes have specific target users that don't have the same requirements as what
was required for this work such as varying number of particles during the
simulation or long range interactions. By building the tools myself I was able
to have more trust in it by subjecting it to rigorous tests and validations.
Additionally, even though a lot of work was put into the creation of this code
base, much time was saved trying to understand or even worst, debug, code from
someone else. Having known at first the amount of time lost on an unstable code
base I would have started my MD package right away as it proved a lot easier
to move forward with it.


The $O(N^2)$ scaling of the MD algorithm prevents simulations of more than tens
of thousands of particles but interesting results are still accessible.

For bigger systems, some algorithm changes can be done to speed the force
calculation on particles. Using a hierarchical tree can change the algorithm
scaling from $O(N^2)$ to $O(N \textrm{log}\pa{N})$ and thus push the limit on
cluster size upward. Having control and full understanding of the code had
the added benefit of easing the process of adding new feature. While the tree
algorithm is implemented, it was not yet used in a publication. An interesting
technology matured during the last decade; by running codes directly on GP-GPUs,
the same algorithms could perform up to one hundred times faster than on
conventional CPUs. The MD package was thus ported to the framework OpenCL where
the MD algorithm shown a speedup of close to 80. This implementation was used
mainly in our publications since the cluster sizes we were interested in were
in the range accessible through MD (and not requiring the tree). The
hierarchical tree-based algorithm is still accessible through an input parameter
(not as an OpenCL implementation though), making the MD package interesting for
future studies where larger clusters will be investigated.

In our first publication in 2011, Edward Ackad, Lora Ramunno and I introduced
the new concept of excited states as a multi-step process of energy transfer
from a laser pulse to rare gas clusters. Because energy is transferred through
collisions, we dubbed this process Augmented Collisional Ionization, or ACI.
With ACI, many more electrons can participate in collisional ionization since
two electrons, successively, participate in the ionization process. Once
electrons loose energy to excited states by collisions, they are slowed down
and

The first study concentrated on Argon clusters in the 32.8 nm regime (37.8 eV).
At this wavelength, only the first two ionization states of (atomic) Argon are
accessible but experiments in 2008 saw up to Ar$^{4+}$. The small cluster sizes
used in the experiment (~100 atoms per cluster) allowed to quickly test and
validate our model. It was found that ACI plays a crucial role in the cluster
dynamics and can explains the high charge states seen in the experiment, with
intensities from $\ten{5}{13}$ to $\ten{10}{13}$~W/cm$^{2}$. When ACI was
enabled in the simulations, the Ar$^{4+}$ population closely matched what was
seen at FLASH. Additionally, the MD simulations allowed tracking the dynamics
of each charge states. It was found that all Ar$^{3+}$ and Ar$^{4+}$ were
created by ACI, making it an vital process in cluster dynamics where traditional
ionization mechanisms cannot explain alone what is seen in laboratories.

``Expansion dynamics'' paper.

Later on, a question presented itself; What is the influence of the cluster
environment on the different states? One of the first books on the
electrodynamics solver called FDTD by Sullivan contained a section on using
this method to solve the \schrodinger equation. Since I was familiar with
the electrodynamics FDTD that I implemented during my masters degree I decided
to explore the quantum version of it. Even though the current implementation is
a single electron picture, a study on the cluster states could still be possible,
at least as a first step. A major problem with FDTD is the amount of memory
required to resolve a three dimensional grid. Normally, FDTD is parallelized
using a shared memory model so it can be distributed on many different
computational nodes. After the work done on implementing the MD algorithm in
OpenCL to run on a GP-GPU, I decided to try porting the QFDTD to OpenCL too
which was actually relatively quick. The video cards could run the code faster,
but video cards have their own discrete memory which is a lot smaller than main
memory. A novel mapping method was thus developed to reduce the number of grid
cell size in the QFDTD computational domain. This new method's innovation comes
from the two space being mapped. Traditionally, one space is mapped to another
one where some physical feature is either enhanced or reduced to ease the numerical
burden. In the nonlinear mapping proposed, one of the space mapped is the actual
discrete memory of the computer; the physical space is mapped to the
integer-referenced memory location through a cumulative sum of a source function,
enforcing the monotonicity required. Due to the way the mapping function is
obtained, any source function can be used, giving great flexibility to the
mapping process. It is thus possible to concentrate grid points around centres
of interest, in this case ions' location.







100 nm paper

