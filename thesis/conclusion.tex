\section{Conclusion}

Clusters of atoms are without a doubt an extremely useful tool to study
laser and matter interaction. They were in used even before atoms were discovered
for their optical properties. With the advancement of both clusters creation
and laser technologies, it became possible to gain a significant understanding
on how light interacts with matter. Clusters studies thus became an important
physics research area.

At the simplest level, quantum mechanic describes the dynamics but exact solutions
are not possible for systems of more than two electrons.
The process of photo-ionization of single atoms is known, but the high density
of atoms inside clusters gives rise to interesting phenomena. It was a surprise
to scientists ten years ago to see highly charged ions coming out of experiments
using rare gas clusters with short duration (tens of femtoseconds), high intensity
(10$^{12}$ -- 10$^{14}$ W/cm$^2$) and small wavelength (VUV, XUV) laser pulses.
More than ten years later, our understanding of the different mechanisms of energy
absorption and diffusion throughout the cluster is taking shape. Even though full
quantum mechanical description of clusters is not possible, small approximations
can be taken, allowing theoretical and numerical studies to be performed.

Our numerical tool of choice is Molecular Dynamics where we track, classically,
the dynamics of electrons and ions during and after a laser pulse. MD simulations,
being classical systems, allows a larger number of particles than full quantum
simulations but can still describe the large fluctuations in charge and field
generated inside a cluster.

Many different MD packages are available freely that could have been used for
the current work. After a first try with one such package, it was decided to
start from scratch a new one. The MD algorithm is relatively simple; having
control on the rest of the package allowed flexibility in the development that
would have not been possible with a third party package. Fore example, existing
MD codes have specific target users that don't have the same requirements as what
was required for this work such as varying number of particles during the
simulation or long range interactions. By building the tools myself I was able
to have more trust in it by subjecting it to rigorous tests and validations.
Additionally, even though a lot of work was put into the creation of this code
base, much time was saved trying to understand or even worst, debug, code from
someone else. Having known at first the amount of time lost on an unstable code
base I would have started my MD package right away as it proved a lot easier
to move forward with it.


The $O(N^2)$ scaling of the MD algorithm prevents simulations of more than tens
of thousands of particles but interesting results are still accessible.

For bigger systems, some algorithm changes can be done to speed the force
calculation on particles. Using a hierarchical tree can change the algorithm
scaling from $O(N^2)$ to $O(N \textrm{log}\pa{N})$ and thus push the limit on
cluster size upward. Having control and full understanding of the code had
the added benefit of easing the process of adding new feature. While the tree
algorithm is implemented, it was not yet used in a publication. An interesting
technology matured during the last decade; by running codes directly on GP-GPUs,
the same algorithms could perform up to one hundred times faster than on
conventional CPUs. The MD package was thus ported to the framework OpenCL where
the MD algorithm shown a speedup of close to 80. This implementation was used
mainly in our publications since the cluster sizes we were interested in were
in the range accessible through MD (and not requiring the tree). The
hierarchical tree-based algorithm is still accessible through an input parameter
(not as an OpenCL implementation though), making the MD package interesting for
future studies where larger clusters will be investigated.

In our first publication in 2011, Edward Ackad, Lora Ramunno and I introduced
the new concept of excited states as a multi-step process of energy transfer
from a laser pulse to rare gas clusters. Because energy is transferred through
collisions, we dubbed this process Augmented Collisional Ionization, or ACI.
With ACI, many more electrons can participate in collisional ionization since
two electrons, successively, participate in the ionization process. Once
electrons loose energy to excited states by collisions, they are slowed down
and

The first study concentrated on Argon clusters in the 32.8 nm regime (37.8 eV).
At this wavelength, only the first two ionization states of (atomic) Argon are
accessible but experiments in 2008 saw up to Ar$^{4+}$. The small cluster sizes
used in the experiment (~100 atoms per cluster) allowed to quickly test and
validate our model. It was found that ACI plays a crucial role in the cluster
dynamics and can explains the high charge states seen in the experiment, with
intensities from $\ten{5}{13}$ to $\ten{10}{13}$~W/cm$^{2}$. When ACI was
enabled in the simulations, the Ar$^{4+}$ population closely matched what was
seen at FLASH. Additionally, the MD simulations allowed tracking the dynamics
of each charge states. It was found that all Ar$^{3+}$ and Ar$^{4+}$ were
created by ACI, making it an vital process in cluster dynamics where traditional
ionization mechanisms cannot explain alone what is seen in laboratories.

``Expansion dynamics'' paper.

Later on, a question presented itself; What is the influence of the cluster
environment on the different states? One of the first books on the
electrodynamics solver called FDTD by Sullivan contained a section on using
this method to solve the \schrodinger equation. Since I was familiar with
the electrodynamics FDTD that I implemented during my masters degree I decided
to explore the quantum version of it. Even though the current implementation is
a single electron picture, a study on the cluster states could still be possible,
at least as a first step. A major problem with FDTD is the amount of memory
required to resolve a three dimensional grid. Normally, FDTD is parallelized
using a shared memory model so it can be distributed on many different
computational nodes. After the work done on implementing the MD algorithm in
OpenCL to run on a GP-GPU, I decided to try porting the QFDTD to OpenCL too
which was actually relatively quick. The video cards could run the code faster,
but video cards have their own discrete memory which is a lot smaller than main
memory. A novel mapping method was thus developed to reduce the number of grid
cell size in the QFDTD computational domain. This new method's innovation comes
from the two space being mapped. Traditionally, one space is mapped to another
one where some physical feature is either enhanced or reduced to ease the numerical
burden. In the nonlinear mapping proposed, one of the space mapped is the actual
discrete memory of the computer; the physical space is mapped to the
integer-referenced memory location through a cumulative sum of a source function,
enforcing the monotonicity required. Due to the way the mapping function is
obtained, any source function can be used, giving great flexibility to the
mapping process. It is thus possible to concentrate grid points around centres
of interest, in this case ions' location. Additionally to the nonlinear mapping,
both real-time and imaginary-time methods were implemented, allowing to compare
the two through the same package. In the case of the imaginary method, a new
way to obtain the eigenstates was described and successively used on the
hydrogen atom and the simplest molecule: hydrogen cation molecule (H$_{2}^{+}$).
Using the real-time method, it was possible to see ten excited states. This
publication allowed to validate the whole technique, including the nonlinear
mapping, and compare with known values from experiments. Going forward, it will
be possible to validate and study some approximations used in the MD package,
for example, what is the influence of the shape of $V_b$ used as the cluster
environment? How much is affected an electron wavefunction by a neighbouring
ion?

The ACI model, based on electron impact cross-sections, is independent of the
regime and does not depend on the laser parameters (pulse duration, wavelength,
intensity, etc.) Transition cross-sections though are unique to each elements
and must be calculated and added to the simulation package before use. Argon
and Xenon cross-sections where generated and are accessible. It is thus
interesting to apply the model to different regimes. Other models were applied
to explain Wabnitz \textit{et al.}'s 2002 VUV-Xenon experiment at FLASH but when the
Bostedt \textit{et al.} published in 2010 a revised intensity (to lower values) it was
though that these models might not be able to reproduce the experimental results
in light of the new, lower intensity. We decided to revisit the 2002 100 nm
experiment in light of our ACI model at the revised, lower intensity.

Thanks to the OpenCL implementation (and its 80 times speedup), it was possible
to acquire significant statistics over a wide range of intensities, effectively
reproducing the clusters distribution in the laser focus spacial profile. This
is an important aspect to reproduce the charge state spectrum seen in experiment
as the clusters normally do not all fall exactly at the laser focus' peak
intensity.

Interestingly, even at the 2.5 times lower intensity ($\ten{8}{12}$~W/cm$^{2}$
vs. $\ten{2}{13}$~W/cm$^{2}$), the experiment's high charge states spectrum
could be reproduced with ACI, something other models couldn't do. ACI had to
be enabled to match the spectrum of the smallest clusters (Xe$_{90}$), both
for the dominant charge state (Xe$^{1+}$) as the maximum charge state (Xe$^{4+}$).
The change from dominant Xe$^{1+}$ to Xe$^{2+}$ was seen to take place at
Xe$_{1415}$ clusters in the simulations, something that couldn't be compared
directly to the experiment. Nevertheless, this transition required ACI to be
enabled, another indication that it plays a major role in cluster dynamics.
Furthermore, the largest clusters in the 2002 experiment was Xe$_{90,000}$, a
cluster size not possible with traditional MD simulations. A parallelized
version of the MD algorithm could be implemented at a later time to explore such
large clusters, or the tree algorithm could be used but would require more
rigorous testing and validation. In any case, a lot of work still need to be
invested to reach these cluster sizes. Another approach could even be taken,
mainly switching from a direct particle-to-particle (PP) algorithm to a more
scalable particle-mesh (PM) or even particle-particle, particle-mesh (P3M)
technique. In these techniques, particles interact through a grid on which their
(static or dynamic) field is propagated, resulting in an algorithm that scales
at $O\pa{N_c^3}$ for the grid cells and $O\pa{N_p}$ for the number of particles,
a lot better than the $O\pa{N_p^2}$ scaling of MD simulations.

An interesting aspect of MD simulations is the effect of the potential depth
used. While many authors set this depth as the first ionization potential, it
is not clear what exact values should be used. As was shown in the last article,
this depth can have a strong influence on the cluster dynamics. In addition, a
different potential shape for the ions (other than Coulombic) could be used to
match the more realistic atomic potential of a mean field approximation. These
kind of potentials were used in rate equations calculations, but could also be
included in MD simulations.


\subsection{Final words}
Theoretical laser-clusters studies is an nice amalgam of many challenging
fields of physics. Clusters, being nanoscopic objects, live in a quantum world
where particles are described by wavefunctions. Then, classical, Newtonian
mechanics can be used to describe some dynamics but the many-body problem that
also arise in astronomy is not solvable analytically, even three hundred years
after Newton. Computers must be used to calculate these simple trajectories
using many different algorithms, bringing computer science into the picture
with all its quirks, problems, bugs, crashes and high expectation algorithms or
new technologies. Lasers are the tool of choice to study the small objects
clusters are. Electrodynamics, classical or quantum, describe light, the purest
form of energy, and its interaction with matter. After clusters get ionized,
the plasma generated can be described with the language of statistical mechanics.
But clusters can be used as a first-order model for biomolecules or can be used
in biological systems. As if physics wasn't complex enough, life itself brings
so many more questions to the picture.

It is easy to be impressed and even overwhelmed by the wide range of fields
touched by clusters studies, but how satisfying can it be to reach so many
topics at once?

What else should a scientist do
after answering a question? If this answer doesn't bring more questions, the
answer could be unsatisfactory.
